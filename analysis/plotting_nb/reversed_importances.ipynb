{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# fix the experimental setting to evaluate\n",
    "dim = 5\n",
    "n_act = 3  # number of actions per agent, has been fixed to 3 in the experiments\n",
    "benchmark = 'piecewise_linear'\n",
    "importance_base = 0.5\n",
    "reward_shape = 'exponential'\n",
    "c = 4.6\n",
    "relevant_approaches = [f'saql_{dim}D', f'sdqn_{dim}D']\n",
    "metric_to_plot = 'avg_reward_test_set'\n",
    "\n",
    "project_name = \"CANDID_DAC\"\n",
    "\n",
    "\n",
    "# Load the data and the experiment configurations\n",
    "performance_metrics = pd.read_csv(f'../run_data/{project_name}_metrics.csv')\n",
    "df_config = pd.read_csv(f'../run_data/{project_name}_configs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the runs by their importance, filtering the config dataframe suffices becaue we use resulting run_ids\n",
    "# to filter the performance metrics\n",
    "print(df_config['reverse_agents'].unique())\n",
    "print(df_config['run_name'].unique())\n",
    "df_config = df_config[\n",
    "    (df_config['dim'] == dim) &\n",
    "    (df_config['benchmark'] == benchmark) &\n",
    "    (df_config['reward_shape'] == reward_shape) &\n",
    "    (df_config['run_name'].isin(relevant_approaches)) & \n",
    "    (df_config['n_act'] == n_act) & \n",
    "    (df_config['exp_reward'] == c) &\n",
    "    (df_config['importance_base'] == importance_base)\n",
    "]\n",
    "\n",
    "# group all runs that share the run_name and discount_submdp and only keep lists of run_id\n",
    "df_grouped = df_config.groupby(['run_name', 'reverse_agents']).agg(list)['run_id']\n",
    "# as control measure group by same attributes and get the seeds, in order\n",
    "seeds_in_group = df_config.groupby(['run_name', 'reverse_agents']).agg(list)['seed']\n",
    "seeds_in_group = seeds_in_group.apply(lambda x: sorted(x))\n",
    "seeds_in_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the best possible avg episodic reward\n",
    "from dacbench.benchmarks import SigmoidBenchmark\n",
    "from plotting_helpers import compute_optimal_episode_reward, get_best_possible_avg_reward\n",
    "import numpy as np\n",
    "\n",
    "optim_reward_per_episode_1D = get_best_possible_avg_reward(dim=dim, n_acts=n_act, benchmark=benchmark, reward_shape=reward_shape, c=c,\n",
    "                                                           importance_base=importance_base, max_dim=1)\n",
    "optim_reward_per_episode_acc = get_best_possible_avg_reward(dim=dim, n_acts=n_act, benchmark=benchmark, reward_shape=reward_shape, c=c,\n",
    "                                                            importance_base=importance_base, max_dim=dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from plotting_helpers import translate_run_name, METHOD_COLOURS\n",
    "# plot the best possible reward\n",
    "\n",
    "\n",
    "# iterate over the groups and plot the performance of each group\n",
    "\n",
    "# plotting color dict for the different approaches\n",
    "# color_dict = {'adqn': 'tab:blue', 'fdqn': 'tab:orange', 'fdqn_a': 'tab:green', 'sdqn': 'tab:red'}\n",
    "plt.rcParams.update({\n",
    "    'font.size': 8,           # Global font size\n",
    "    'axes.titlesize': 7,      # Title size of individual plots\n",
    "    'axes.labelsize': 7,      # Label size for x and y labels\n",
    "    'xtick.labelsize': 6.5,      # Size of x-tick labels\n",
    "    'ytick.labelsize': 6.5,      # Size of y-tick labels\n",
    "    'legend.fontsize': 7,      # Size of the legend text\n",
    "    'figure.titlesize': 12,     # Title size of the entire figure\n",
    "    'lines.linewidth': 0.75\n",
    "})\n",
    "fig = plt.figure(figsize=(3, 1.6))\n",
    "plt.plot(np.full(10000, optim_reward_per_episode_acc), color='black', linestyle='--', label='optimal')\n",
    "plt.plot(np.full(10000, optim_reward_per_episode_1D), color='grey', linestyle='--', label='optimal (1D)')\n",
    "\n",
    "for (name, reverse_agents), group in df_grouped.items():\n",
    "    # remove the dimensionality from the run_name by removing the characters after the last underscore\n",
    "    name = name[:name.rfind('_')]\n",
    "    color = METHOD_COLOURS[name]\n",
    "#     dashes = [1, 2] if reverse_agents else [1, 0]\n",
    "    label = translate_run_name(name)\n",
    "    label += ' (reversed importances)' if reverse_agents else ''\n",
    "    relevant_data = performance_metrics[performance_metrics['run_id'].isin(group)]\n",
    "    relevant_data = relevant_data[['_step', metric_to_plot]].groupby('_step').agg(['mean', 'std'])\n",
    "    relevant_data.dropna(inplace=True)\n",
    "    plt.plot(relevant_data.index / 10, relevant_data[metric_to_plot]['mean'], label=label, color=color, linestyle='-' if not reverse_agents else '--')\n",
    "            #  linewidth=0.8) \n",
    "    plt.fill_between(relevant_data.index / 10, relevant_data[metric_to_plot]['mean'] - relevant_data[metric_to_plot]['std'],\n",
    "                     relevant_data[metric_to_plot]['mean'] + relevant_data[metric_to_plot]['std'], alpha=0.4, facecolor=color)\n",
    "\n",
    "max_epoch = performance_metrics['_step'].max() / 10\n",
    "\n",
    "plt.xlim(left=0, right=10000)\n",
    "plt.ylim(bottom=0, top=10)\n",
    "plt.axis('on')\n",
    "\n",
    "plt.xticks(np.linspace(0, 10000, 5))\n",
    "plt.yticks(np.linspace(0, 10, 5))\n",
    "\n",
    "# plt.title(f'Exponential importance sigmoid ($c = {c}$)')\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Avg. episodic reward')\n",
    "\n",
    "# plt.legend()\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# plt.suptitle(f'Sequential policies on {dim}D CANDID Sigmoid benchmark', fontweight='bold')\n",
    "\n",
    "# place plot a bit further from the title\n",
    "plt.subplots_adjust(top=0.85)\n",
    "plt.savefig(f'./paper_plots/pl_reversed_importances.png', dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

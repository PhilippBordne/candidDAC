{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "project_name = 'CANDID_DAC'\n",
    "\n",
    "run_id_to_plot = '58x8jy9x' # SAQL on 5D CANDID Sigmoid\n",
    "run_id_to_plot = 'oi9p2pvs' # SDQN on 5D CANDID Sigmoid\n",
    "\n",
    "\n",
    "dim = 5\n",
    "# importance_sigmoid = False\n",
    "importance_base = 0.5\n",
    "reward_shape = 'exponential'\n",
    "exp_reward = 4.6\n",
    "\n",
    "config_path = f'../run_data/{project_name}_configs.csv'\n",
    "# path_to_ckpts = f'../../results/{project_name}/run_{run_id_to_plot}/'\n",
    "\n",
    "config_df = pd.read_csv(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from plotting_helpers import load_policy_from_checkpoint\n",
    "from dacbench.benchmarks import SigmoidBenchmark\n",
    "import numpy as np\n",
    "# locate the last checkpoint of the run\n",
    "checkpoint_dir = f'../../results/models/{project_name}/{run_id_to_plot}'\n",
    "\n",
    "# get the environment to plot on\n",
    "\n",
    "importances = np.array([importance_base**i for i in range(dim)])\n",
    "env = SigmoidBenchmark().get_importances_benchmark(dimension=dim, importances=importances, reward_shape=reward_shape)\n",
    "\n",
    "config = config_df[config_df['run_id'] == run_id_to_plot].iloc[0].to_dict()\n",
    "policy = load_policy_from_checkpoint(config=config, env=env, ckpt_directory=checkpoint_dir, episode=10000, final=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the policy on several instances of the importance benchmark and plot the results\n",
    "import numpy as np\n",
    "from candid_dac.policies import AtomicPolicy\n",
    "import torch\n",
    "\n",
    "truth_on_instances = []\n",
    "actions_on_instances = []\n",
    "obtained_rewards = []\n",
    "\n",
    "actions = np.zeros((dim, env.n_steps))\n",
    "truth = np.zeros((dim, env.n_steps))\n",
    "\n",
    "# instances_ids = [0, 50, 100, 150, 200, 299] # if importance_sigmoid else [None]  # only plot on single instance if not importance sigmoid\n",
    "instances_ids = np.linspace(0, 299, 6, endpoint=True, dtype=int)\n",
    "print(instances_ids)\n",
    "# inst_id = 15\n",
    "\n",
    "for i, inst_id in enumerate(instances_ids):\n",
    "    # env.use_next_instance(instance_id=inst_id)\n",
    "    obs, _ = env.reset(instance_id=inst_id)\n",
    "    obtained_reward = 0\n",
    "    # if not importance_sigmoid:\n",
    "    # for i in range(inst_id):\n",
    "    #     obs, _ = env.reset()\n",
    "\n",
    "    for t in range(env.n_steps):\n",
    "        if isinstance(policy, AtomicPolicy):\n",
    "            action = policy(torch.tensor(obs))\n",
    "            action = np.unravel_index(action, env.action_space.nvec)\n",
    "        else:\n",
    "            action = policy.get_action(obs)\n",
    "        obs, reward, terminated, truncated, _ = env.step(action)\n",
    "        obtained_reward += reward\n",
    "        actions[:, t] = action\n",
    "\n",
    "    actions_on_instances.append(actions.copy())\n",
    "    obtained_rewards.append(obtained_reward)\n",
    "\n",
    "    points_in_time = np.linspace(0, env.n_steps - 1, 100, endpoint=True)\n",
    "    truth_on_instances.append(env._sig(points_in_time, env.slopes[0], env.shifts[0]))\n",
    "\n",
    "print(len(truth_on_instances))\n",
    "print(len(actions_on_instances))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "from plotting_helpers import translate_run_name\n",
    "print(env.inst_id)\n",
    "# plot truth and actions on each dimension in a separate plot\n",
    "rows = len(truth_on_instances) // 3\n",
    "plt.rcParams.update({\n",
    "    'font.size': 8,           # Global font size\n",
    "    'axes.titlesize': 7,      # Title size of individual plots\n",
    "    'axes.labelsize': 7,      # Label size for x and y labels\n",
    "    'xtick.labelsize': 6.5,      # Size of x-tick labels\n",
    "    'ytick.labelsize': 6.5,      # Size of y-tick labels\n",
    "    'legend.fontsize': 7,      # Size of the legend text\n",
    "    'figure.titlesize': 12,     # Title size of the entire figure\n",
    "    'lines.linewidth': 0.75,\n",
    "    'lines.markersize': 2.5,\n",
    "\n",
    "})\n",
    "width = 6 # latex textwidth\n",
    "fig, axs = plt.subplots(rows, 3, figsize=(6, 6/2.5), sharex=True, sharey=True)\n",
    "\n",
    "algorithm = translate_run_name(run_name=config['run_name'])\n",
    "\n",
    "for inst, ax in enumerate(axs.flatten()):\n",
    "    ax.set_title(f'Instance {instances_ids[inst]}')\n",
    "    truth = truth_on_instances[inst]\n",
    "    actions = actions_on_instances[inst]\n",
    "    ax.plot(points_in_time, truth, label='sigmoid target', color='tab:orange')\n",
    "\n",
    "    # use a color map to color the actions according to the dimension\n",
    "    colors = plt.cm.viridis(np.linspace(1, 0, dim))\n",
    "\n",
    "    for i in range(dim):\n",
    "        action = env.compute_pred_from_actions(actions, level=i+1)\n",
    "        # ax.plot(np.arange(env.n_steps), action, label=f'{algorithm} agent prediction (up to dim {i+1})', color=colors[i])\n",
    "        ax.scatter(np.arange(env.n_steps), action, label=f'{algorithm} agent prediction (up to dim {i+1})', color=colors[i],\n",
    "                   alpha=0.5 + 0.5 * (i+1) / dim, zorder=i+10, edgecolors='none')\n",
    "        ax.set_xticks(range(0, env.n_steps, 1))\n",
    "        ax.set_yticks(np.linspace(0, 1, 6))\n",
    "        # ax.set_yticks(np.linspace(0, 1, 3))\n",
    "        # ax.set_xlabel('$t$')\n",
    "    ax.plot(np.arange(env.n_steps), action, linestyle=':', label=f'{algorithm} agent prediction (full)', color=colors[-1])\n",
    "    # ax.scatter(np.arange(env.n_steps), action, label=f'{algorithm} agent prediction', color='red', marker='x')\n",
    "\n",
    "    # scatter the final aggregated prediction\n",
    "    action = env.compute_pred_from_actions(actions)\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib import cm\n",
    "colors = plt.cm.viridis_r(np.linspace(0, 1, dim-1))\n",
    "# create a customized legend with a colorbar below it\n",
    "custom_lines = [Line2D([0], [0], color=\"tab:orange\", linestyle=\"-\", label=\"target\"),\n",
    "                Line2D([0], [0], linestyle=\"None\", marker=\"o\", color=\"gray\", label=\"partially aggr. prediction\"),\n",
    "                Line2D([0], [0], color=colors[-1], linestyle=\":\", label=\"final prediction\"),]\n",
    "legend = axs[0, -1].legend(loc='center left', bbox_to_anchor=(1, -0.2), handles=custom_lines)\n",
    "# Get the bounding box of the legend\n",
    "legend_box = legend.get_window_extent()\n",
    "# Convert the bounding box from display units to figure units\n",
    "legend_box_fig = legend_box.transformed(fig.transFigure.inverted())\n",
    "# Create new axes for the colorbar below the legend\n",
    "cbar_ax = fig.add_axes([legend_box_fig.x0, legend_box_fig.y0 - 0.1, legend_box_fig.width, 0.05])\n",
    "# Create color bar with manually specified ticks\n",
    "cbar = fig.colorbar(cm.ScalarMappable(cmap=cm.viridis_r, norm=plt.Normalize(vmin=dim-1, vmax=0)),\n",
    "                    cax=cbar_ax, ticks=np.arange(dim), orientation='horizontal')\n",
    "cbar.ax.tick_params(length=0)  # Remove ticks\n",
    "# cbar.ax.xaxis.set_label_coords(0.5, -0.5)  # Position the label\n",
    "cbar.set_label('aggregated dimensions')\n",
    "\n",
    "\n",
    "\n",
    "for ax in axs[:, 0]:\n",
    "    ax.set_ylabel('prediction value')\n",
    "for ax in axs[rows-1, :]:\n",
    "    ax.set_xlabel('$t$')\n",
    "# # place the legend to the right of the last plot\n",
    "# axs[0, -1].legend(loc='center left', bbox_to_anchor=(1, -0.2))\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.15)\n",
    "print(f\"Algorithm: {algorithm}\")\n",
    "# fig.suptitle(f\"{algorithm} agent on instances of {dim}D CANDID Sigmoid\", fontweight='bold')\n",
    "# plt.show()\n",
    "fig.savefig(f'./paper_plots/{"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

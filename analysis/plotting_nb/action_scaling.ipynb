{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "project_name = \"CANDID_DAC\"\n",
    "# set up the experiment we want to plot\n",
    "benchmark = \"piecewise_linear\"\n",
    "reward_shape = 'exponential'\n",
    "exp_reward = 4.6\n",
    "importance_base = 0.5\n",
    "n_acts = [3, 5, 10]\n",
    "dim = 5\n",
    "\n",
    "metric_to_plot = \"avg_reward_train_set\"\n",
    "# metric_to_plot = \"avg_episodic_reward\"\n",
    "config_path = f\"../run_data/{project_name}_configs.csv\"\n",
    "metrics_path = f\"../run_data/{project_name}_metrics.csv\"\n",
    "\n",
    "df_configs = pd.read_csv(config_path)\n",
    "df_train = pd.read_csv(metrics_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the configs per benchmark dimensionality\n",
    "configs = df_configs[(df_configs['benchmark'] == benchmark) &\n",
    "                     (df_configs['reward_shape'] == reward_shape) &\n",
    "                     (df_configs['exp_reward'] == exp_reward) &\n",
    "                     (df_configs['importance_base'] == importance_base) &\n",
    "                     (df_configs['n_act'].isin(n_acts)) &\n",
    "                     (df_configs['dim'] == dim) &\n",
    "                     (df_configs['reverse_agents'] == False)]\n",
    "\n",
    "print(configs['n_act'].unique())\n",
    "\n",
    "grouped_configs = configs.groupby(['run_name', 'n_act']).agg(list)['run_id']\n",
    "print(len(grouped_configs))\n",
    "# as control measure group by same attributes and get the seeds, in order\n",
    "seeds_in_group = configs.groupby(['run_name', 'n_act']).agg(['count', list])['seed']\n",
    "seeds_in_group = seeds_in_group.apply(lambda x: sorted(x))\n",
    "# seeds_in_group\n",
    "grouped_configs.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_configs = df_configs[(df_configs['name'] == 'ddqn') & (df_configs['dim'] == 5) & (df_configs['n_act'] == 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "from plotting_helpers import get_best_possible_avg_reward, translate_run_name, METHOD_COLOURS\n",
    "\n",
    "# width = 12\n",
    "# fig, axes = plt.subplots(1, len(n_acts), figsize=(width, width / len(n_acts)), sharey=True)\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.size': 8,           # Global font size\n",
    "    'axes.titlesize': 7,      # Title size of individual plots\n",
    "    'axes.labelsize': 6,      # Label size for x and y labels\n",
    "    'xtick.labelsize': 6,      # Size of x-tick labels\n",
    "    'ytick.labelsize': 6,      # Size of y-tick labels\n",
    "    'legend.fontsize': 7,      # Size of the legend text\n",
    "    'figure.titlesize': 12,     # Title size of the entire figure\n",
    "    'lines.linewidth': 0.5\n",
    "})\n",
    "width = 6\n",
    "dpi=100  # set to 100 to get in size of paper not zoomed in\n",
    "fig, axes = plt.subplots(1, len(n_acts), figsize=(width, width / 5), sharey=True, dpi=dpi, )\n",
    "\n",
    "for i, n_act in enumerate(n_acts):\n",
    "    ax = axes[i]\n",
    "\n",
    "    # plot the best possible reward\n",
    "    optimal_reward_1D = get_best_possible_avg_reward(dim=dim, benchmark=benchmark, reward_shape=reward_shape, c=exp_reward,\n",
    "                                                     importance_base=importance_base, max_dim=1, n_acts=n_act)\n",
    "    optimal_reward_acc = get_best_possible_avg_reward(dim=dim, benchmark=benchmark, reward_shape=reward_shape, c=exp_reward,\n",
    "                                                      importance_base=importance_base, max_dim=dim, n_acts=n_act)\n",
    "\n",
    "    ax.plot([0, 10000], [optimal_reward_acc, optimal_reward_acc], label='optimal', color='black', linestyle='--')\n",
    "    ax.plot([0, 10000], [optimal_reward_1D, optimal_reward_1D], label='optimal (1D)', color='grey', linestyle='--')\n",
    "\n",
    "    # only keep the runs for this dimensionality\n",
    "    dim_configs = grouped_configs.xs(n_act, level='n_act')\n",
    "\n",
    "    # now plot rewards per approach, which is encoded by run_name\n",
    "    for run_name, run_ids in dim_configs.items():\n",
    "        run_name = run_name.rsplit('_', 1)[0]\n",
    "        label = translate_run_name(run_name)\n",
    "        color = METHOD_COLOURS[run_name]\n",
    "\n",
    "        # get the rewards for this run, drop all undefined time steps\n",
    "        rewards = df_train.loc[df_train['run_id'].isin(run_ids)].groupby('_step')[metric_to_plot].agg(['mean', 'std'])\n",
    "        rewards = rewards.dropna()\n",
    "        \n",
    "        # plot the mean and std\n",
    "        ax.fill_between(rewards.index / 10, rewards['mean'] - rewards['std'], rewards['mean'] + rewards['std'], alpha=0.5, color=color)\n",
    "        ax.plot(rewards.index / 10, rewards['mean'], label=label, color=color)\n",
    "\n",
    "        # make the plot square, regardless of scaling difference in x and y\n",
    "        ax.set_ylim(0, 10.07)\n",
    "        ax.set_xlim(0, 10000)\n",
    "        ax.tick_params(axis='x', pad=-5)\n",
    "\n",
    "        title = f'n_act = {n_act}'\n",
    "        ax.set_title(title, y=0.94)\n",
    "        ax.set_xlabel('Episodes')\n",
    "\n",
    "# set the same y-axis label for all plots\n",
    "y_label = 'Avg. episodic reward'\n",
    "axes[0].set_ylabel(y_label)\n",
    "# set a shared legend, centered under the plots, considering that legends is identical for all plots\n",
    "axes[-1].legend(loc='center left', bbox_to_anchor=(1, 0.5), ncol=1)\n",
    "# axes[-1].legend(['mean, std'], loc='center left', bbox_to_anchor=(1, 0.5), ncol=1)\n",
    "\n",
    "fig.subplots_adjust(wspace=0.15,)\n",
    "fig.savefig(f'./paper_plots/n_acts_scaling.png', bbox_inches='tight', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
